# @package model.sequence
# Stage 2: Note sequence generation model configuration
vocab_size: 167  # Must match tokenizer.VOCAB_SIZE
d_model: 512
nhead: 8
num_layers: 8
dim_feedforward: 2048
num_difficulties: 5
num_genres: 1  # Disabled â€” 100% of maps have genre="unknown"
dropout: 0.1

# Training
learning_rate: 0.0003
weight_decay: 0.01
max_seq_length: 64  # Max tokens per onset timestamp
label_smoothing: 0.1
freeze_encoder: false

# Dataset
context_frames: 128  # Mel frames around each onset for audio context

# Difficulty filtering (null = all difficulties)
difficulties:
  - Expert
  - ExpertPlus

# Inference
beam_size: 8
temperature: 1.0
top_p: 0.9  # Nucleus sampling threshold
